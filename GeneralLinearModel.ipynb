{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luisalvarez/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import nibabel as nib\n",
    "from nilearn.plotting import plot_img, plot_stat_map, view_img, plot_prob_atlas\n",
    "from nilearn.regions import connected_label_regions\n",
    "from nilearn.glm.first_level.hemodynamic_models import spm_hrf\n",
    "from nilearn.image import concat_imgs, mean_img, index_img, smooth_img\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.glm import threshold_stats_img\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn.plotting import plot_roi\n",
    "from nilearn.maskers import NiftiMapsMasker, NiftiSpheresMasker\n",
    "from nilearn.image import high_variance_confounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir : /Users/luisalvarez/Documents/Datasets\n"
     ]
    }
   ],
   "source": [
    "# Open a datasets directory. \n",
    "fd = os.open(\"/Users/luisalvarez/Documents/Datasets\", os.O_RDONLY)\n",
    "\n",
    "# Use os.fchdir() method to change the current dir/folder.\n",
    "os.fchdir(fd)\n",
    "\n",
    "# Safe check- Print current working directory\n",
    "print(\"Current working dir : %s\" % os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0z/1yt2h6410kb7_mgghf4q28z00000gn/T/ipykernel_11452/2947252213.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  sub01_events = pd.read_csv('/Users/luisalvarez/Documents/GitHub/RM_Thesis_Neuroforecasting/ProcessedData/sub-01/sub-01_processed_events.csv', sep='\\,')\n",
      "/var/folders/0z/1yt2h6410kb7_mgghf4q28z00000gn/T/ipykernel_11452/2947252213.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub01_run1_events_base.rename(columns={\"Type\": \"trial_type\", \"Onset\": \"onset\"}, inplace=True)\n",
      "/var/folders/0z/1yt2h6410kb7_mgghf4q28z00000gn/T/ipykernel_11452/2947252213.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub01_run1_events_base[\"duration\"] = 5\n",
      "/var/folders/0z/1yt2h6410kb7_mgghf4q28z00000gn/T/ipykernel_11452/2947252213.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub01_run2_events_base.rename(columns={\"Type\": \"trial_type\", \"Onset\": \"onset\"}, inplace=True)\n",
      "/var/folders/0z/1yt2h6410kb7_mgghf4q28z00000gn/T/ipykernel_11452/2947252213.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub01_run2_events_base[\"duration\"] = 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial_type</th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>modulation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Horror</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.029333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Horror</td>\n",
       "      <td>60.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.292443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>108.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.319109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Horror</td>\n",
       "      <td>152.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.276443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Horror</td>\n",
       "      <td>196.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.029333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trial_type  onset  duration  modulation\n",
       "0     Horror   12.0         5    0.029333\n",
       "1     Horror   60.0         5    0.292443\n",
       "2     Comedy  108.0         5   -0.319109\n",
       "3     Horror  152.0         5   -0.276443\n",
       "4     Horror  196.0         5    0.029333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data from sub-01. \n",
    "\n",
    "sub01_events = pd.read_csv('/Users/luisalvarez/Documents/GitHub/RM_Thesis_Neuroforecasting/ProcessedData/sub-01/sub-01_processed_events.csv', sep='\\,')\n",
    "\n",
    "# Separate into run 1 and run 2. \n",
    "sub01_run1 = sub01_events.iloc[:16, :]\n",
    "sub01_run2 = sub01_events.iloc[16:, :]\n",
    "sub01_run1.reset_index(drop=True, inplace=True)\n",
    "sub01_run2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Should I adjust onsets for the time lag (the same way we did for the timecourse analysis)?\n",
    "\n",
    "# Now, create different events df's for different modulation types.\n",
    "\n",
    "sub01_run1_events_base = sub01_run1[[\"Type\", \"Onset\"]]\n",
    "sub01_run1_events_base.rename(columns={\"Type\": \"trial_type\", \"Onset\": \"onset\"}, inplace=True)\n",
    "sub01_run1_events_base[\"duration\"] = 5\n",
    "# Adjust time lag... \n",
    "sub01_run2_events_base = sub01_run2[[\"Type\", \"Onset\"]]\n",
    "sub01_run2_events_base.rename(columns={\"Type\": \"trial_type\", \"Onset\": \"onset\"}, inplace=True)\n",
    "sub01_run2_events_base[\"duration\"] = 5\n",
    "\n",
    "sub01_run1_events_PA = sub01_run1_events_base.copy()\n",
    "sub01_run1_events_PA[\"modulation\"] = sub01_run1[\"Pos_arousal_scaled\"]\n",
    "\n",
    "sub01_run2_events_PA = sub01_run2_events_base.copy()\n",
    "sub01_run2_events_PA[\"modulation\"] = sub01_run2[\"Pos_arousal_scaled\"]\n",
    "\n",
    "sub01_run1_events_PA.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load confound files. \n",
    "sub01_run1_confounds = \"MovieData_BIDS_preproc/sub-\" + \"01\" + \"/func/sub-\" + \"01\" + \"_task-movie_run-01_desc-confounds_regressors.tsv\"\n",
    "sub01_run2_confounds = \"MovieData_BIDS_preproc/sub-\" + \"01\" + \"/func/sub-\" + \"01\" + \"_task-movie_run-02_desc-confounds_regressors.tsv\"\n",
    "\n",
    "sub01_run1_confounds = pd.read_csv(sub01_run1_confounds, sep='\\t')\n",
    "sub01_run2_confounds = pd.read_csv(sub01_run2_confounds, sep='\\t')\n",
    "\n",
    "# Define default confounds and \n",
    "default_confounds = [\"white_matter\", \"csf\", \"csf_wm\", \"framewise_displacement\", \"dvars\", \"rmsd\", \"tcompcor\",     \n",
    "                    'w_comp_cor_00', 'w_comp_cor_01', 'w_comp_cor_02', 'w_comp_cor_03', 'w_comp_cor_04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sub01 functional data.\n",
    "sub01_run1_func = \"MovieData_BIDS_preproc/sub-\" + \"01\" + \"/func/sub-\" + \"01\" + \"_task-movie_run-01_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\"\n",
    "sub01_run2_func = \"MovieData_BIDS_preproc/sub-\" + \"01\" + \"/func/sub-\" + \"01\" + \"_task-movie_run-02_space-MNI152NLin2009cAsym_desc-preproc_bold.nii.gz\"\n",
    "\n",
    "# Load mask file.\n",
    "sub01_run1_mask = \"MovieData_BIDS_preproc/sub-\" + \"01\" + \"/func/sub-\" + \"01\" + \"_task-movie_run-01_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz\"\n",
    "sub01_run2_mask = \"MovieData_BIDS_preproc/sub-\" + \"01\" + \"/func/sub-\" + \"01\" + \"_task-movie_run-02_space-MNI152NLin2009cAsym_desc-brain_mask.nii.gz\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create first level model.\n",
    "first_level_model = FirstLevelModel(t_r=2.0, \n",
    "                                    hrf_model='spm', \n",
    "                                    high_pass=1/360, \n",
    "                                    smoothing_fwhm=4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
